---
title: "Predicting daily Citibike trips"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)

#helper method to load trips and reshape them
loadTrips <- function(location)
{
  load(location)
  temp.trips <- trips %>% 
    group_by(ymd) %>% 
    summarize(count=n()) %>% 
    left_join(weather,by="ymd") %>% 
    filter(!is.na(tmin)) %>%
    mutate(weekday = weekdays(ymd), month = month(ymd)) %>%
    mutate(weekend=(weekday == "Sunday" | weekday == "Saturday"))
  

  #adding lagged weather data
  temp.trips.lagged <- temp.trips %>% mutate (ymd = ymd+1)
  temp.trips.lagged <- merge(temp.trips.lagged,temp.trips, by="ymd", suffixes=c(".prev",""))
  return (temp.trips.lagged)
}

#loading 2015 data
trips.2015 <-loadTrips("2015/trips.RData")
#loading 2014 data
trips.2014 <-loadTrips("2014/trips.RData")
```


#### The point of this exercise is to get experience in an open-ended prediction exercise: predicting the total number of Citibike trips taken on a given day. Do all of your work in an RMarkdown file named predict_citibike.Rmd. Here are the rules of the game: 

1. You can use any features you like that are available prior to the day in question, ranging from the weather, to the time of year and day of week, to activity in previous days or weeks, but don't cheat and use features from the future (e.g., the next day's trips).
    ```{r q1}
    
    #weekend day
    model.1.formula <- count ~ prcp + weekday 
    
    ggplot(trips_weather_weekday, aes(x=ymd,y=count)) + geom_point() + facet_wrap(facets=~weekend)
    
    ggplot(trips_weather_weekday, aes(x=ymd,y=count)) + geom_point()
    
    ```
    
    ```{r test}
    #tests a given list of models against a given list of test_datas
    testModel <- function(models, test_datas)
    {
      results <- list();
      counter <- 1;
      for (i in 1:length(models))
      {
        results[[i]] <- list();
        model <- models[[i]];
        for (j in 1:length(test_datas))
        {
          data <- test_datas[[j]];
          output <- toString(model$terms[[2]]);
          yHat <- predict(model,data);
          rSquared <- cor(yHat,data[[output]])^2;
          rsme <- sqrt(mean((yHat-data[[output]])^2));
          results[[i]][[j]] <-c(rSquared,rsme);
        }
      }
      return (results);
    }
    
    #returns a list of models based on a given formula
    trainModel <- function(formulas, training_data)
    {
      results <- list();
      for (i in length(formulas))
      {
        results[[i]] <- lm(data=training_data, formula=formulas[[i]]);
      }
      return (results);      
    }
    
    #splits the data into multiple parititions
    kfold <- function(data, k)
    {
      training <- list();
      test <- list();
      temp.random <- sample(data);
      lineCount <- 1:nrow(data)%%k+1;
      
      temp.ranked <- cbind(temp.random,p=lineCount)
      for (i in 1:k)
      {
        test[[i]] <- temp.ranked %>% filter(p==i);
        training[[i]] <- temp.ranked %>% filter(p != i);
        
      }
      return (list(training=training,test=test))
    }
    
    
    #our formula
    formulas <- list(
      count~
        poly(tmin,2) + 
        snwd.prev + 
        poly(count.prev,2) + 
        prcp + 
        weekend + 
        snow.prev + 
        I(snwd^5) + I(snwd^3) + I(snwd^2) + snwd)
    
    set.seed(1);
    #create training and test data from trips.2014
    data <- kfold(trips.2014,5)
    #train the model with only one partition
    models <- trainModel(formulas,data$training[[1]])

    #add data from 2015 as test data
    testDatas <- c()
    testDatas[[1]] <- data$test[[1]];
    testDatas[[2]] <- trips.2015;

    result <- testModel(models,testDatas) 
    print(paste("rSquared for 2014 test data(20% of total data): ",result[[1]][[1]][[1]]))
    print(paste("rmse for 2014 test data(20% of total data): ",result[[1]][[1]][[2]]))
    print(paste("rSquared for 2015 test data: ",result[[1]][[2]][[1]]))
    print(paste("rmse for 2015 test data: ",result[[1]][[2]][[2]]))
    ```
2. As usual, split your data into training and testing subsets and evaluate performance on each.

3. Quantify your performance in two ways: R^2 (or the square of the correlation coefficient), as we've been doing, and with root mean-squared error.

4. Report the model with the best performance on the test data. Watch out for overfitting.

5. Plot your final best fit model in two different ways. First with the date on the x-axis and the number of trips on the y-axis, showing the actual values as points and predicted values as a line. Second as a plot where the x-axis is the predicted value and the y-axis is the actual value, with each point representing one day.

6. Inspect the model when you're done to figure out what the highly predictive features are, and see if you can prune away any negligble features that don't matter much.